{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu, chi2_contingency\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "from copy import deepcopy\n",
    "import pip install dataframe_image as dfi\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, fbeta_score, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf530a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\pavan\\OneDrive\\Desktop\\sem2\\ML\\Project\\Android_Malware.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29383fb6",
   "metadata": {},
   "source": [
    "# Inspection and Dropping Columns, Missing Values, Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c390ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,[56,58,63]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5933b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,58].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,56].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,63].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.iloc[:,58] == 'BENIGN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CWE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate',\n",
    "           'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'ECE Flag Count',\n",
    "           'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'RST Flag Count']\n",
    "\n",
    "for column in columns:\n",
    "    unique_counts = df[column].value_counts()\n",
    "    print(f\"Unique values and their counts for {column}:\\n{unique_counts}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=['Unnamed: 0','CWE Flag Count','Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk','Fwd Avg Bulk Rate',\n",
    "                      'Bwd Avg Bytes/Bulk','Bwd Avg Packets/Bulk','Bwd Avg Bulk Rate','ECE Flag Count',\n",
    "                      'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'RST Flag Count',\n",
    "                      'Timestamp', 'Flow ID'])\n",
    "\n",
    "df = df.drop(index=276556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.shape)\n",
    "\n",
    "null_rows = df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91610d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Rows to be dropped:\")\n",
    "print(null_rows.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9723f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93115561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbc647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Resulting DataFrame:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e70c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920553e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[['Protocol', 'Fwd PSH Flags', 'FIN Flag Count', 'SYN Flag Count', 'PSH Flag Count',\n",
    "    'ACK Flag Count', 'URG Flag Count', 'Down/Up Ratio']] \\\n",
    "= df[['Protocol', 'Fwd PSH Flags', 'FIN Flag Count', 'SYN Flag Count', 'PSH Flag Count',\n",
    "      'ACK Flag Count', 'URG Flag Count', 'Down/Up Ratio']].apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[['Protocol', 'Fwd PSH Flags', 'FIN Flag Count', 'SYN Flag Count', 'PSH Flag Count',\n",
    "    'ACK Flag Count', 'URG Flag Count', 'Down/Up Ratio']] \\\n",
    "= df[['Protocol', 'Fwd PSH Flags', 'FIN Flag Count', 'SYN Flag Count', 'PSH Flag Count', \n",
    "      'ACK Flag Count', 'URG Flag Count', 'Down/Up Ratio']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f7612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2832d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Protocol','Fwd PSH Flags','FIN Flag Count','SYN Flag Count',\n",
    "    'PSH Flag Count','ACK Flag Count','URG Flag Count']] \\\n",
    "= df[['Protocol','Fwd PSH Flags','FIN Flag Count','SYN Flag Count',\n",
    "    'PSH Flag Count','ACK Flag Count','URG Flag Count']].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d380f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff408656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ip_to_decimal(ip):\n",
    "    # Split the IP address into octets\n",
    "    octets = ip.split('.')\n",
    "    binary = '{0:08b}{1:08b}{2:08b}{3:08b}'.format(*map(int, octets))\n",
    "    decimal = int(binary, 2) # Convert binary to decimal\n",
    "    return decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Source IP Decimal'] = df['Source IP'].apply(ip_to_decimal)\n",
    "df['Destination IP Decimal'] = df['Destination IP'].apply(ip_to_decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4206fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Target'] = df['Label'].apply(lambda x: 1 if x.startswith('Android_') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069fd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=['Source IP', 'Destination IP','Label'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea948c0",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize = (20,20))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7370c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = df.select_dtypes(include='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keep_num_df = pd.DataFrame(columns=['Feature', 'Statistic', 'p-value'])\n",
    "exclude_num_df = pd.DataFrame(columns=['Feature', 'Statistic', 'p-value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in numeric_cols[:-1]:\n",
    "    malware = df.loc[df['Target'] == 1, col]\n",
    "    benign = df.loc[df['Target'] == 0, col]\n",
    "    stat, p = mannwhitneyu(malware, benign)\n",
    "    if p < 0.05:\n",
    "        keep_num_df = pd.concat([keep_num_df, pd.DataFrame({'Feature': [col], 'Statistic': [stat], 'p-value': [p.round(3)]})], ignore_index=True)\n",
    "    else:\n",
    "        exclude_num_df = pd.concat([exclude_num_df, pd.DataFrame({'Feature': [col], 'Statistic': [stat], 'p-value': [p.round(3)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Features to keep:\")\n",
    "print(keep_num_df)\n",
    "\n",
    "print(\"\\nFeatures to exclude:\")\n",
    "print(exclude_num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5524ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keep_num_df.shape)\n",
    "print(exclude_num_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "object_cols = df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a33a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keep_cat_df = pd.DataFrame(columns=['Feature', 'Chi2 Statistic', 'p-value'])\n",
    "exclude_cat_df = pd.DataFrame(columns=['Feature', 'Chi2 Statistic', 'p-value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa54daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in object_cols:\n",
    "    contingency_table = pd.crosstab(df[col], df['Target'])\n",
    "    chi2, p, dof, _ = chi2_contingency(contingency_table)\n",
    "    if p < 0.05:\n",
    "        keep_cat_df = pd.concat([keep_cat_df, pd.DataFrame({'Feature': [col], 'Chi2 Statistic': [chi2], 'p-value': [p.round(5)]})], ignore_index=True)\n",
    "    else:\n",
    "        exclude_cat_df = pd.concat([exclude_cat_df, pd.DataFrame({'Feature': [col], 'Chi2 Statistic': [chi2], 'p-value': [p.round(3)]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Features to keep:\")\n",
    "print(keep_cat_df)\n",
    "print(\"\\nFeatures to exclude:\")\n",
    "print(exclude_cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in df.select_dtypes(include=['int', 'float', 'object']).columns:\n",
    "    top_value = df[col].value_counts(normalize=True).nlargest(1)\n",
    "    if top_value.iloc[0] > 0.5:\n",
    "        print(f'Column {col}:\\n\\t top value = {top_value.index[0]}\\n\\t frequency = {top_value.iloc[0]:.2f}\\n\\t type: {df[col].dtype}\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc821f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b70272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece73f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7365dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize the final data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eaab8c",
   "metadata": {},
   "source": [
    "# Preprocessing - Training - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_features = list(keep_num_df.Feature) + list(keep_cat_df.Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_features = list(exclude_cat_df.Feature)+list(exclude_num_df.Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_var = 'Target'\n",
    "X = df[keep_features]\n",
    "y = df[targ_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7acbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[keep_features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f7eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[targ_var].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_cols = ['Protocol', 'PSH Flag Count', 'ACK Flag Count']\n",
    "numeric_cols = ['Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Fwd Packet Length Max', \n",
    "                'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', \n",
    "                'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', \n",
    "                'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Max', 'Fwd Header Length', 'Bwd Header Length', \n",
    "                'Min Packet Length', 'Packet Length Std', 'Packet Length Variance', 'Down/Up Ratio', 'Avg Fwd Segment Size', \n",
    "                'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', \n",
    "                'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward', \n",
    "                'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Max', 'Idle Min', \n",
    "                'Source IP Decimal', 'Destination IP Decimal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09590c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = [\n",
    "    ('RandomForestClassifier', RandomForestClassifier(random_state=42)),\n",
    "    ('XGBClassifier', XGBClassifier(random_state=42)),\n",
    "    ('LGBMClassifier', LGBMClassifier(random_state=42))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessors = [\n",
    "    ('StandardScaler', ColumnTransformer(transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ], remainder='passthrough')),\n",
    "    ('MinMaxScaler', ColumnTransformer(transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', MinMaxScaler(), numeric_cols)\n",
    "    ], remainder='passthrough')),\n",
    "    ('RobustScaler', ColumnTransformer(transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', RobustScaler(), numeric_cols)\n",
    "    ], remainder='passthrough'))\n",
    "]\n",
    "\n",
    "samplers = [\n",
    "    ('SMOTE', SMOTE(random_state=42))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc15386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_pipeline = None\n",
    "best_score = -np.inf\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac374d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scoring = {\n",
    "    'fbeta': make_scorer(fbeta_score, beta=2, average='weighted'),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted'),\n",
    "    'accuracy': make_scorer(accuracy_score, average='weighted')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for clf_name, classifier in tqdm(classifiers, desc='Classifier', leave=False):\n",
    "    for pre_name, preprocessor in tqdm(preprocessors, desc='Preprocessor', leave=False):\n",
    "        for samp_name, sampler in tqdm(samplers, desc='Sampler', leave=False):\n",
    "            # Create a pipeline\n",
    "            pipeline = make_pipeline(\n",
    "                preprocessor,\n",
    "                sampler,\n",
    "                classifier\n",
    "            )\n",
    "            \n",
    "            # Calculate the cross-validated scores\n",
    "            cv_scores = cross_validate(pipeline, X_train, y_train, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "            \n",
    "            # Calculate and store the results\n",
    "            results.append({\n",
    "                'Classifier': clf_name,\n",
    "                'Preprocessor': pre_name,\n",
    "                'Sampler': samp_name,\n",
    "                'CV f2 Score': np.mean(cv_scores['test_fbeta']),\n",
    "                'CV F1': np.mean(cv_scores['test_f1']),\n",
    "                'CV Recall': np.mean(cv_scores['test_recall']),\n",
    "                'CV Precision': np.mean(cv_scores['test_precision']),\n",
    "                'CV Accuracy': np.mean(cv_scores['test_accuracy'])  \n",
    "            })\n",
    "\n",
    "            # Update the best values if the f0.5 score is higher\n",
    "            if np.mean(cv_scores['test_fbeta']) > best_score:\n",
    "                best_score = np.mean(cv_scores['test_fbeta'])\n",
    "                best_pipeline = pipeline\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf170cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "joblib.dump(best_pipeline, 'best_pipeline.pkl')\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# Assuming 'best_pipeline' is the pipeline with the best configuration\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Generate and print the imbalanced classification report\n",
    "class_report_imbalanced = classification_report_imbalanced(y_test, y_pred)\n",
    "print(class_report_imbalanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02492a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f8f91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Retrieve the preprocessor and sampler from the best_pipeline\n",
    "    preprocessor = best_pipeline.named_steps['columntransformer']\n",
    "    sampler = best_pipeline.named_steps['smote']\n",
    "\n",
    "    # Suggest hyperparameters for RandomForestClassifier\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 25, 34)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 5)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 1)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
    "\n",
    "  \n",
    "    classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                        max_features=max_features, random_state=42, verbose=1, n_jobs=-1)\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, sampler, classifier)\n",
    "\n",
    "  \n",
    "    cv_scores = cross_validate(pipeline, X_train, y_train, scoring=make_scorer(fbeta_score, beta=2, average='weighted'), cv=cv, n_jobs=-1)\n",
    "    trial.set_user_attr(\"pipeline\", pipeline)\n",
    "\n",
    "\n",
    "    return np.mean(cv_scores['test_score'])\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10) \n",
    "\n",
    "\n",
    "best_trial = study.best_trial\n",
    "best_pipeline_optimized = best_trial.user_attrs[\"pipeline\"]\n",
    "\n",
    "print(\"Best hyperparameters:\", best_trial.params)\n",
    "print(\"Best F2 score:\", best_trial.value)\n",
    "\n",
    "# Fit the updated best_pipeline to the entire training set\n",
    "best_pipeline_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Save the updated best_pipeline to a pickle file\n",
    "joblib.dump(best_pipeline_optimized, 'best_pipeline_optimized.pkl')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfc_base = best_pipeline.named_steps['randomforestclassifier']\n",
    "rfc_optimized = best_pipeline_optimized.named_steps['randomforestclassifier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Steps in best_pipeline.pkl:\", best_pipeline.named_steps.keys())\n",
    "print(\"Steps in best_pipeline_optimized.pkl:\", best_pipeline_optimized.named_steps.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74546db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "class_report_imbalanced = classification_report_imbalanced(y_test, y_pred)\n",
    "print(class_report_imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108402f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators_base = rfc_base.n_estimators\n",
    "min_samples_split_base = rfc_base.min_samples_split\n",
    "min_samples_leaf_base = rfc_base.min_samples_leaf\n",
    "max_features_base = rfc_base.max_features\n",
    "max_depth_base = max([tree.tree_.max_depth for tree in rfc_base.estimators_])\n",
    "\n",
    "\n",
    "n_estimators_optimized = rfc_optimized.n_estimators\n",
    "min_samples_split_optimized = rfc_optimized.min_samples_split\n",
    "min_samples_leaf_optimized = rfc_optimized.min_samples_leaf\n",
    "max_features_optimized = rfc_optimized.max_features\n",
    "max_depth_optimized = max([tree.tree_.max_depth for tree in rfc_optimized.estimators_])\n",
    "\n",
    "# Find the index of the best_pipeline in the results DataFrame\n",
    "best_pipeline_index = results_df.loc[results_df['CV f2 Score'] == best_score].index[0]\n",
    "\n",
    "\n",
    "# Extract the mean cross-validated F2 score of the best_pipeline\n",
    "# Get the best F2 scores from the hyperparameter tuning process\n",
    "f2_score_base = results_df.loc[best_pipeline_index, 'CV f2 Score']\n",
    "f2_score_optimized = best_trial.value\n",
    "\n",
    "\n",
    "# Create a dictionary with the attributes as keys and their values as lists\n",
    "attributes_dict = {\n",
    "    'f2_score_training': [f2_score_base, f2_score_optimized],\n",
    "    'max_depth': [max_depth_base, max_depth_optimized],\n",
    "    'n_estimators': [n_estimators_base, n_estimators_optimized],\n",
    "    'min_samples_split': [min_samples_split_base, min_samples_split_optimized],\n",
    "    'min_samples_leaf': [min_samples_leaf_base, min_samples_leaf_optimized],\n",
    "    'max_features': [max_features_base, max_features_optimized],\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "comparison_df = pd.DataFrame(attributes_dict, index=['rfc_base', 'rfc_optimized'])\n",
    "\n",
    "# Display the DataFrame\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results DataFrame after hyperparameter tuning\n",
    "results_after_tuning = {\n",
    "    'Classifier': ['RandomForestClassifier'],\n",
    "    'Preprocessor': ['Optimized'],\n",
    "    'Sampler': ['Optimized'],\n",
    "    'CV f2 Score': [best_trial.value],\n",
    "    'CV F1': [np.nan],  # Replace with actual F1 score after tuning\n",
    "    'CV Recall': [np.nan],  # Replace with actual recall after tuning\n",
    "    'CV Precision': [np.nan],  # Replace with actual precision after tuning\n",
    "    'CV Accuracy': [np.nan],  # Replace with actual accuracy after tuning\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d23f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results DataFrame before hyperparameter tuning\n",
    "results_df_before_tuning = pd.DataFrame(results)\n",
    "\n",
    "# Print or display the results before tuning\n",
    "print(\"Results Before Hyperparameter Tuning:\")\n",
    "display(results_df_before_tuning)\n",
    "\n",
    "# ... (rest of your code)\n",
    "\n",
    "# Results DataFrame after hyperparameter tuning\n",
    "results_after_tuning = {\n",
    "    'Classifier': ['RandomForestClassifier'],\n",
    "    'Preprocessor': ['Optimized'],\n",
    "    'Sampler': ['Optimized'],\n",
    "    'CV f2 Score': [best_trial.value],\n",
    "    'CV F1': [np.nan],  # Replace with actual F1 score after tuning\n",
    "    'CV Recall': [np.nan],  # Replace with actual recall after tuning\n",
    "    'CV Precision': [np.nan],  # Replace with actual precision after tuning\n",
    "    'CV Accuracy': [np.nan],  # Replace with actual accuracy after tuning\n",
    "}\n",
    "\n",
    "results_df_after_tuning = pd.DataFrame(results_after_tuning)\n",
    "\n",
    "# Compare the results before and after tuning\n",
    "comparison_df = pd.concat([results_df_before_tuning, results_df_after_tuning], ignore_index=True)\n",
    "\n",
    "# Display the comparison DataFrame\n",
    "print(\"Comparison of Results Before and After Hyperparameter Tuning:\")\n",
    "display(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c3dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87333c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create a DummyClassifier with the 'stratified' strategy\n",
    "dummy_clf = DummyClassifier(strategy='stratified', random_state=42)\n",
    "\n",
    "# Preprocess the X_train and X_test data using the preprocessor from best_pipeline_optimized\n",
    "preprocessor = best_pipeline_optimized.named_steps['columntransformer']\n",
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply the sampler to the preprocessed X_train data\n",
    "sampler = best_pipeline_optimized.named_steps['smote']\n",
    "X_train_preprocessed_resampled, y_train_resampled = sampler.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "# Fit the DummyClassifier on the preprocessed and resampled training data and make predictions\n",
    "dummy_clf.fit(X_train_preprocessed_resampled, y_train_resampled)\n",
    "y_pred_dummy = dummy_clf.predict(X_test_preprocessed)\n",
    "\n",
    "# Make predictions using best_pipeline_optimized\n",
    "y_pred_optimized = best_pipeline_optimized.predict(X_test)\n",
    "\n",
    "# Calculate F2 scores\n",
    "f2_score_dummy = fbeta_score(y_test, y_pred_dummy, beta=2, average='weighted')\n",
    "f2_score_optimized = fbeta_score(y_test, y_pred_optimized, beta=2, average='weighted')\n",
    "\n",
    "# Create a DataFrame with the F2 scores\n",
    "f2_test_scores_df = pd.DataFrame({\n",
    "    'Classifier': ['Dummy Classifier', 'rfc_optimized'],\n",
    "    'F2 Score': [f2_score_dummy, f2_score_optimized]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "display(f2_test_scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c76499",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score\n",
    "\n",
    "\n",
    "def display_values(ax, cm, fontsize=16):\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, f'{cm[i, j] * 100:.1f}%', ha='center', va='center', color='black', fontsize=fontsize)\n",
    "\n",
    "# Calculate confusion matrices\n",
    "cm_dummy = confusion_matrix(y_test, y_pred_dummy, normalize='all', labels=[1, 0])\n",
    "cm_optimized = confusion_matrix(y_test, y_pred_optimized, normalize='all', labels=[1, 0])\n",
    "\n",
    "# Transpose confusion matrices and swap columns\n",
    "cm_dummy = cm_dummy.T\n",
    "cm_optimized = cm_optimized.T\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "fig.suptitle(\"Comparing Baseline with Model\", fontsize=25, x=.5, y=1.05)\n",
    "\n",
    "cmap = plt.get_cmap('Spectral')\n",
    "norm = plt.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "# Plot dummy classifier confusion matrix\n",
    "im = ax1.imshow(cm_dummy, cmap=cmap, norm=norm)\n",
    "ax1.set_title('Dummy Classifier Confusion Matrix')\n",
    "ax1.set_xticks([0, 1])\n",
    "ax1.set_yticks([0, 1])\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.xaxis.set_ticks_position('both')\n",
    "ax1.xaxis.set_label_position('top')\n",
    "ax1.set_xlabel('Actual')\n",
    "ax1.set_xticklabels(['Malware (1)', 'Benign (0)'])\n",
    "ax1.set_yticklabels(['Malware (1)', 'Benign (0)'])\n",
    "ax1.set_ylabel('Predicted')\n",
    "ax1.add_patch(Rectangle((-.485, .5), .98, 1, fill=False, edgecolor='black', lw=4))\n",
    "ax1.annotate('False Negative', xy=(0.02, .9), xycoords='data', fontsize=12, ha='center', va='bottom', color='black')\n",
    "ax1.annotate('False Positive', xy=(1, -.1), xycoords='data', fontsize=12, ha='center', va='bottom', color='black')\n",
    "\n",
    "# Plot optimized pipeline confusion matrix\n",
    "ax2.imshow(cm_optimized, cmap=cmap, norm=norm)\n",
    "ax2.set_title('Optimized Pipeline Confusion Matrix')\n",
    "ax2.set_xticks([0, 1])\n",
    "ax2.set_yticks([0, 1])\n",
    "ax2.xaxis.tick_top()\n",
    "ax2.xaxis.set_ticks_position('both')\n",
    "ax2.xaxis.set_label_position('top')\n",
    "ax2.set_xlabel('Actual')\n",
    "ax2.set_xticklabels(['Malware (1)', 'Benign (0)'])\n",
    "ax2.set_yticklabels(['Malware (1)', 'Benign (0)'])\n",
    "ax2.set_ylabel('Predicted')\n",
    "ax2.add_patch(Rectangle((-.48, .5), .98, 1, fill=False, edgecolor='black', lw=4))\n",
    "ax2.annotate('False Negative', xy=(0.02, .9), xycoords='data', fontsize=12, ha='center', va='bottom', color='black')\n",
    "ax2.annotate('False Positive', xy=(1, -.1), xycoords='data', fontsize=12, ha='center', va='bottom', color='black')\n",
    "\n",
    "display_values(ax1, cm_dummy)\n",
    "display_values(ax2, cm_optimized)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "cbar_ax = fig.add_axes([0.93, 0.15, 0.03, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax, format='%.2f')\n",
    "plt.savefig('confusion_matrices.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# Compute prediction probabilities\n",
    "y_pred_dummy_prob = dummy_clf.predict_proba(X_test_preprocessed)\n",
    "y_pred_optimized_prob = best_pipeline_optimized.predict_proba(X_test)\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision_dummy, recall_dummy, _ = precision_recall_curve(y_test, y_pred_dummy_prob[:, 1])\n",
    "precision_optimized, recall_optimized, _ = precision_recall_curve(y_test, y_pred_optimized_prob[:, 1])\n",
    "\n",
    "# Calculate F2 score for the baseline classifier\n",
    "f2_score_baseline = fbeta_score(y_test, y_pred_dummy, beta=2)\n",
    "\n",
    "# Calculate Average Precision (AP) scores\n",
    "ap_dummy = average_precision_score(y_test, y_pred_dummy_prob[:, 1])\n",
    "ap_optimized = average_precision_score(y_test, y_pred_optimized_prob[:, 1])\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_dummy, precision_dummy, label=f'Dummy Classifier (AP = {ap_dummy:.2f})', linestyle='--')\n",
    "plt.plot(recall_optimized, precision_optimized, label=f'Optimized Model (AP = {ap_optimized:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.savefig('precision_recall_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances from the Random Forest model\n",
    "rfc = best_pipeline_optimized.named_steps['randomforestclassifier']\n",
    "feature_importances = rfc.feature_importances_\n",
    "\n",
    "# Get the feature names from the preprocessor\n",
    "preprocessor_feature_importance = best_pipeline_optimized.named_steps['columntransformer']\n",
    "feature_names = preprocessor_feature_importance.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the top 10 most important features\n",
    "top_n = 10\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(importances_df['Feature'].str.replace('num__','')[:top_n], importances_df['Importance'][:top_n])\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add the Flow IAT annotation\n",
    "annotation = (\"Flow IAT (Inter-Arrival Time) measures the time between the arrival of data packets in a network.\\n\")\n",
    "plt.annotate(annotation, xy=(0.2, 0.85), xycoords='axes fraction', fontsize=10, ha='left', va='bottom', wrap=True)\n",
    "\n",
    "plt.subplots_adjust(bottom=0.2)  # Adjust the bottom margin\n",
    "plt.savefig('important_features.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the desired class labels\n",
    "df['Class'] = df['Target'].map({0: 'Benign', 1: 'Malware'})\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='Flow IAT Max', y='Flow IAT Min', hue='Class', palette='viridis', alpha=0.7)\n",
    "plt.title(\"Most Important Features (Actual Labels)\")\n",
    "plt.savefig('best_features_original.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature indices for Flow IAT Max and Flow IAT Min from the preprocessor\n",
    "flow_iat_max_index = list(feature_names).index('num__Flow IAT Max')\n",
    "flow_iat_min_index = list(feature_names).index('num__Flow IAT Min')\n",
    "\n",
    "# Extract Flow IAT Max and Flow IAT Min from the preprocessed test data\n",
    "flow_iat_max_preprocessed = X_test_preprocessed[:, flow_iat_max_index]\n",
    "flow_iat_min_preprocessed = X_test_preprocessed[:, flow_iat_min_index]\n",
    "\n",
    "# Create a DataFrame with Flow IAT Max, Flow IAT Min, and the predicted labels\n",
    "flow_iat_predicted_df = pd.DataFrame({\n",
    "    'Flow IAT Max': flow_iat_max_preprocessed,\n",
    "    'Flow IAT Min': flow_iat_min_preprocessed,\n",
    "    'Predicted Label': y_pred_optimized\n",
    "})\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=flow_iat_predicted_df, x='Flow IAT Max', y='Flow IAT Min', hue='Predicted Label', palette='viridis', alpha=0.7)\n",
    "plt.title(\"Scatterplot of 'Flow IAT Max' vs 'Flow IAT Min' (Predicted Labels)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = df.head(10).iloc[:, :10].style.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(odd)', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(even)', 'props': [('background-color', '#303030'), ('color', '#f0f0f0')]},\n",
    "    ]).hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_df = results_df.sort_values(by='CV f2 Score',ascending=False)\n",
    "model_selection_df = model_selection_df.style.background_gradient(subset='CV f2 Score', cmap='viridis').set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(odd)', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(even)', 'props': [('background-color', '#303030'), ('color', '#f0f0f0')]},\n",
    "    ]).hide(axis=\"index\")\n",
    "model_selection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c787ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tune_model_comparison_df = comparison_df.style.background_gradient(subset=['max_depth','n_estimators'], cmap='viridis').set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(odd)', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(even)', 'props': [('background-color', '#303030'), ('color', '#f0f0f0')]},\n",
    "    ])\n",
    "base_tune_model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba67e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_test_scores_df.style.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(odd)', 'props': [('background-color', '#424242'), ('color', '#f0f0f0')]},\n",
    "        {'selector': 'tr:nth-child(even)', 'props': [('background-color', '#303030'), ('color', '#f0f0f0')]},\n",
    "    ]).hide(axis=\"index\").highlight_max(subset=['F2 Score'], color='#78C257')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `new_row` is the row without the target variable\n",
    "# You should replace the values in `new_row` with the actual values you want to predict\n",
    "new_row = X_test.iloc[0, :]\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_data = pd.DataFrame([new_row])\n",
    "\n",
    "# Ensure the column order and data types match the training data\n",
    "new_data = new_data[keep_features]  # Assuming `keep_features` is the list of features used in training\n",
    "\n",
    "# Use the same preprocessing steps as in the training phase\n",
    "preprocessor = best_pipeline_optimized.named_steps['columntransformer']\n",
    "new_data_preprocessed = preprocessor.transform(new_data)\n",
    "\n",
    "\n",
    "# Use the trained and optimized pipeline to predict the target\n",
    "predicted_target = best_pipeline_optimized.predict(new_data_preprocessed)\n",
    "\n",
    "# Map the numeric prediction to the corresponding label\n",
    "predicted_label = 'Malware' if predicted_target == 1 else 'Benign'\n",
    "\n",
    "# Display the result\n",
    "print(f\"The predicted label for the given row is: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e434964",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_row=X_test.iloc[0, :]\n",
    "new_data = pd.DataFrame([f_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5617ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae7c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
